# 4.2 训练流程与超参数

大模型预训练是一个庞大且复杂的系统工程，涉及数周甚至数月的持续计算。一个稳定、高效的训练流程至关重要。

## 1. 训练流程 (Training Loop)

一个典型的预训练流程如下：

1.  **数据加载**: 从经过处理的数据集中分批（batch）加载数据。
2.  **前向传播 (Forward Pass)**:
    *   将一批数据输入模型。
    *   模型计算输出（logits）。
    *   根据输出和真实标签计算损失（Loss）。
3.  **反向传播 (Backward Pass)**:
    *   根据损失计算模型参数的梯度。
4.  **优化器步骤 (Optimizer Step)**:
    *   优化器（如 AdamW）根据梯度更新模型的权重。
    *   清空梯度，为下一次迭代做准备。
5.  **学习率调度 (Learning Rate Scheduling)**:
    *   根据当前训练步数调整学习率。
6.  **日志与监控**: 记录损失、学习率、吞吐量等关键指标。
7.  **Checkpointing**: 定期保存模型的权重、优化器状态和训练状态。

## 2. 关键超参数 (Hyperparameters)

*   **学习率 (Learning Rate)**:
    *   **描述**: 控制模型权重更新的步长，可能是最重要的超参数。
    *   **学习率调度器 (LR Scheduler)**: 动态调整学习率的策略。最常用的是**余弦退火调度器 (Cosine Annealing Scheduler)**，通常带有一个预热（Warmup）阶段。
        *   **Warmup**: 在训练初期，将学习率从一个很小的值线性增加到峰值，有助于训练初期的稳定性。
        *   **Decay**: 在 Warmup 之后，学习率按照余弦曲线逐渐衰减到一个最小值。

*   **批次大小 (Batch Size)**:
    *   **描述**: 每次迭代中用于计算梯度的样本数量。
    *   **全局批次大小 (Global Batch Size)**: 在所有 GPU 上一次处理的总样本数。`Global Batch Size = 每个 GPU 的批次大小 × 梯度累积步数 × GPU 数量`。
    *   **影响**: 批次大小越大，梯度估计越稳定，但显存消耗也越大。通常认为在一定范围内，越大的批次大小对训练越有利。

*   **梯度累积 (Gradient Accumulation)**:
    *   **描述**: 一种在不增加显存消耗的情况下，模拟大批次训练的技术。通过多次前向和反向传播累积梯度，然后用累积的梯度进行一次权重更新。

## 3. Checkpointing 与断点续训

由于大模型训练时间长，硬件故障或其它中断是常态，因此健壮的 Checkpointing 机制是必需的。

*   **Checkpoint 内容**: 需要保存的不仅仅是模型权重，还包括：
    *   **优化器状态**: 如 Adam 的一阶和二阶动量。
    *   **学习率调度器状态**: 当前的步数和学习率。
    *   **随机数生成器状态**: 保证从断点恢复后数据加载和 dropout 等是可复现的。
    *   **训练状态**: 当前的 epoch, step 等。

*   **策略**: 
    *   定期（如每隔 N 个 step）保存 Checkpoint。
    *   在分布式训练中，需要确保所有进程同步保存，以保证状态的一致性。
    *   通常会保存多个最近的 Checkpoint，以防最新的一个损坏。
