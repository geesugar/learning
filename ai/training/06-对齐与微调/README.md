# 第 6 章：对齐与微调

本章重点介绍如何通过微调技术，使预训练好的基础模型更好地理解和遵循人类指令，并适配特定领域的任务。

## 学习内容

1.  [**指令微调 (Supervised Fine-tuning, SFT)**](./01-指令微调.md)
    *   学习如何使用高质量的问答数据对，让模型学会遵循指令。

2.  [**人类反馈强化学习 (RLHF)**](./02-RLHF.md)
    *   通过流程图理解 RLHF 的复杂三阶段过程，了解如何让模型输出更符合人类偏好。

3.  [**参数高效微调 (PEFT)**](./03-参数高效微调.md)
    *   通过图解深入理解 LoRA 等技术，学习如何在有限资源下高效地进行微调。

4.  [**微调技术对比**](./04-微调技术对比.md)
    *   通过表格和场景分析，清晰地了解全量微调、PEFT 和 RLHF 的优缺点及适用场景，帮助在实践中做出正确的技术选型。