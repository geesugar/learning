# 6.3 参数高效微调 (Parameter-Efficient Fine-tuning, PEFT)

PEFT 技术旨在通过仅微调模型的一小部分参数，来显著降低计算和存储成本，同时达到与全量微调相当的性能。

*   **核心思想**: 冻结大部分预训练模型参数，仅在模型中添加或修改少量可训练参数。

*   **主流 PEFT 方法**:
    *   **LoRA (Low-Rank Adaptation)**
        *   **原理**: LoRA 的核心假设是，模型在微调时其权重的变化量（`ΔW`）是一个低秩矩阵。因此，可以用两个更小的低秩矩阵（`A` 和 `B`）的乘积来模拟 `ΔW`。在前向传播时，将这个模拟的 `ΔW` 加到原始权重 `W` 上。

        ```plantuml
        @startuml
        !theme vibrant
        title LoRA (Low-Rank Adaptation) Principle

        cloud "Input (x)" as Input

        rectangle "Pre-trained Weight (W)" as W #lightblue {
          note top: Frozen, not updated
        }

        rectangle "LoRA Adapter" as Adapter #lightgreen {
          rectangle "Matrix A" as A
          rectangle "Matrix B" as B
          note top: Trainable, low-rank
          A -> B : Rank `r` is small
        }
        
        rectangle "Output (h)" as Output

        Input -> W : h_orig = W * x
        Input -> A : x
        A -> B : B * (A * x)
        B -> Output : h = h_orig + (B*A*x)
        W -> Output

        note right of Adapter
          The update `ΔW` is approximated by `B * A`.
          `h = W*x + ΔW*x = W*x + B*A*x`
          Only A and B are trained.
        end note
        @enduml
        ```

        *   **实现细节**: 在实践中，这通常被应用到 Transformer 的自注意力模块的查询（Query）和值（Value）投射矩阵上。通过 `peft` 库，可以非常容易地将 LoRA 应用到任意线性层。

    *   **QLoRA (Quantized LoRA)**
        *   **原理**: 结合 LoRA 与模型量化技术。首先将预训练模型加载为 4-bit 的量化模型（极大地降低了基础显存），然后在这个冻结的 4-bit 模型之上，添加 LoRA 适配器进行微调。适配器本身仍然以更高精度（如 16-bit）进行训练。
        *   **效果**: 使得在消费级 GPU（如 24GB 显存）上微调大型模型（如 65B 参数）成为可能。

    *   **Adapter Tuning**: 在 Transformer 的每个块（Block）中的多头注意力和前馈网络之后，插入一个非常小的、独立的神经网络模块（称为“适配器”）。微调时只训练这些适配器的参数。

    *   **Prompt Tuning / P-Tuning**: 不改变任何模型权重，而是在输入端为每个任务学习一组特定的、连续的向量（soft prompt），将它们与真实的输入嵌入拼接在一起，引导模型执行特定任务。

    *   **Prefix Tuning**: 与 Prompt Tuning 类似，但在 Transformer 的每一层都添加可训练的前缀向量，给予模型在每一层改变其行为的能力，功能比 Prompt Tuning 更强大。

*   **PEFT 库**: Hugging Face 的 `peft` 库是目前应用这些技术的事实标准，它提供了统一、简洁的 API 来实现 LoRA、Prompt Tuning 等多种 PEFT 方法。