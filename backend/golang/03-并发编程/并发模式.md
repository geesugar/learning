# 并发模式

## 学习目标
- 掌握常用的Go并发设计模式
- 理解Pipeline和Fan-out/Fan-in模式
- 学习Worker Pool和生产者消费者模式
- 掌握超时和取消模式的实现

## 1. Worker Pool模式

### 基本Worker Pool
```go
type Job struct {
    ID   int
    Data interface{}
}

type Result struct {
    Job    Job
    Output interface{}
    Error  error
}

type WorkerPool struct {
    workerCount int
    jobQueue    chan Job
    resultQueue chan Result
    quit        chan bool
}

func NewWorkerPool(workerCount, jobQueueSize, resultQueueSize int) *WorkerPool {
    return &WorkerPool{
        workerCount: workerCount,
        jobQueue:    make(chan Job, jobQueueSize),
        resultQueue: make(chan Result, resultQueueSize),
        quit:        make(chan bool),
    }
}

func (wp *WorkerPool) Start() {
    for i := 0; i < wp.workerCount; i++ {
        go wp.worker(i)
    }
}

func (wp *WorkerPool) worker(id int) {
    fmt.Printf("Worker %d 启动\n", id)
    
    for {
        select {
        case job := <-wp.jobQueue:
            fmt.Printf("Worker %d 处理任务 %d\n", id, job.ID)
            
            // 模拟工作处理
            result := wp.processJob(job)
            wp.resultQueue <- result
            
        case <-wp.quit:
            fmt.Printf("Worker %d 停止\n", id)
            return
        }
    }
}

func (wp *WorkerPool) processJob(job Job) Result {
    // 模拟处理时间
    time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond)
    
    // 模拟处理逻辑
    output := fmt.Sprintf("处理结果: %v", job.Data)
    
    return Result{
        Job:    job,
        Output: output,
        Error:  nil,
    }
}

func (wp *WorkerPool) Submit(job Job) {
    wp.jobQueue <- job
}

func (wp *WorkerPool) GetResult() Result {
    return <-wp.resultQueue
}

func (wp *WorkerPool) Stop() {
    close(wp.quit)
    close(wp.jobQueue)
}

// 使用示例
func workerPoolExample() {
    pool := NewWorkerPool(3, 10, 10)
    pool.Start()
    
    // 提交任务
    for i := 0; i < 10; i++ {
        job := Job{
            ID:   i,
            Data: fmt.Sprintf("数据-%d", i),
        }
        pool.Submit(job)
    }
    
    // 收集结果
    for i := 0; i < 10; i++ {
        result := pool.GetResult()
        if result.Error != nil {
            fmt.Printf("任务 %d 错误: %v\n", result.Job.ID, result.Error)
        } else {
            fmt.Printf("任务 %d 完成: %v\n", result.Job.ID, result.Output)
        }
    }
    
    pool.Stop()
}
```

### 可配置的Worker Pool
```go
type WorkerConfig struct {
    WorkerCount     int
    JobQueueSize    int
    ResultQueueSize int
    ProcessTimeout  time.Duration
    RetryCount      int
}

type AdvancedWorkerPool struct {
    config      WorkerConfig
    jobQueue    chan Job
    resultQueue chan Result
    workers     []chan bool
    wg          sync.WaitGroup
}

func NewAdvancedWorkerPool(config WorkerConfig) *AdvancedWorkerPool {
    return &AdvancedWorkerPool{
        config:      config,
        jobQueue:    make(chan Job, config.JobQueueSize),
        resultQueue: make(chan Result, config.ResultQueueSize),
        workers:     make([]chan bool, config.WorkerCount),
    }
}

func (awp *AdvancedWorkerPool) Start() {
    for i := 0; i < awp.config.WorkerCount; i++ {
        workerQuit := make(chan bool)
        awp.workers[i] = workerQuit
        
        awp.wg.Add(1)
        go awp.advancedWorker(i, workerQuit)
    }
}

func (awp *AdvancedWorkerPool) advancedWorker(id int, quit chan bool) {
    defer awp.wg.Done()
    
    for {
        select {
        case job := <-awp.jobQueue:
            result := awp.processJobWithRetry(job, id)
            awp.resultQueue <- result
            
        case <-quit:
            fmt.Printf("高级Worker %d 停止\n", id)
            return
        }
    }
}

func (awp *AdvancedWorkerPool) processJobWithRetry(job Job, workerID int) Result {
    for attempt := 0; attempt < awp.config.RetryCount; attempt++ {
        result := awp.processJobWithTimeout(job, workerID, attempt)
        
        if result.Error == nil {
            return result
        }
        
        fmt.Printf("Worker %d 任务 %d 重试 %d: %v\n", 
                   workerID, job.ID, attempt+1, result.Error)
        
        if attempt < awp.config.RetryCount-1 {
            time.Sleep(time.Duration(attempt+1) * 100 * time.Millisecond)
        }
    }
    
    return Result{
        Job:   job,
        Error: fmt.Errorf("任务失败，已重试 %d 次", awp.config.RetryCount),
    }
}

func (awp *AdvancedWorkerPool) processJobWithTimeout(job Job, workerID, attempt int) Result {
    resultChan := make(chan Result, 1)
    
    go func() {
        // 模拟可能失败的工作
        time.Sleep(time.Duration(rand.Intn(2000)) * time.Millisecond)
        
        if rand.Float32() < 0.3 { // 30% 失败率
            resultChan <- Result{
                Job:   job,
                Error: fmt.Errorf("随机失败"),
            }
        } else {
            resultChan <- Result{
                Job:    job,
                Output: fmt.Sprintf("Worker %d 完成任务 %d (尝试 %d)", workerID, job.ID, attempt+1),
            }
        }
    }()
    
    select {
    case result := <-resultChan:
        return result
    case <-time.After(awp.config.ProcessTimeout):
        return Result{
            Job:   job,
            Error: fmt.Errorf("任务超时"),
        }
    }
}

func (awp *AdvancedWorkerPool) Stop() {
    close(awp.jobQueue)
    
    for _, workerQuit := range awp.workers {
        close(workerQuit)
    }
    
    awp.wg.Wait()
    close(awp.resultQueue)
}
```

## 2. Pipeline模式

### 简单Pipeline
```go
// Pipeline阶段函数类型
type Stage func(<-chan interface{}) <-chan interface{}

// 创建Pipeline
func Pipeline(stages ...Stage) Stage {
    return func(input <-chan interface{}) <-chan interface{} {
        output := input
        for _, stage := range stages {
            output = stage(output)
        }
        return output
    }
}

// 阶段1：数据生成
func dataGenerator(nums ...int) <-chan interface{} {
    out := make(chan interface{})
    
    go func() {
        defer close(out)
        for _, num := range nums {
            out <- num
        }
    }()
    
    return out
}

// 阶段2：数据转换（平方）
func squareStage(input <-chan interface{}) <-chan interface{} {
    out := make(chan interface{})
    
    go func() {
        defer close(out)
        for value := range input {
            if num, ok := value.(int); ok {
                out <- num * num
            }
        }
    }()
    
    return out
}

// 阶段3：数据过滤（只保留偶数）
func filterEvenStage(input <-chan interface{}) <-chan interface{} {
    out := make(chan interface{})
    
    go func() {
        defer close(out)
        for value := range input {
            if num, ok := value.(int); ok && num%2 == 0 {
                out <- num
            }
        }
    }()
    
    return out
}

// 阶段4：数据格式化
func formatStage(input <-chan interface{}) <-chan interface{} {
    out := make(chan interface{})
    
    go func() {
        defer close(out)
        for value := range input {
            out <- fmt.Sprintf("结果: %v", value)
        }
    }()
    
    return out
}

// Pipeline使用示例
func pipelineExample() {
    // 创建数据源
    input := dataGenerator(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
    
    // 构建pipeline
    pipeline := Pipeline(squareStage, filterEvenStage, formatStage)
    
    // 执行pipeline
    output := pipeline(input)
    
    // 收集结果
    for result := range output {
        fmt.Println(result)
    }
}
```

### 可配置的Pipeline
```go
type PipelineConfig struct {
    BufferSize    int
    WorkerCount   int
    EnableLogging bool
}

type ConfigurablePipeline struct {
    config PipelineConfig
    stages []func(<-chan interface{}, PipelineConfig) <-chan interface{}
}

func NewConfigurablePipeline(config PipelineConfig) *ConfigurablePipeline {
    return &ConfigurablePipeline{
        config: config,
        stages: make([]func(<-chan interface{}, PipelineConfig) <-chan interface{}, 0),
    }
}

func (cp *ConfigurablePipeline) AddStage(stage func(<-chan interface{}, PipelineConfig) <-chan interface{}) {
    cp.stages = append(cp.stages, stage)
}

func (cp *ConfigurablePipeline) Execute(input <-chan interface{}) <-chan interface{} {
    output := input
    
    for i, stage := range cp.stages {
        if cp.config.EnableLogging {
            fmt.Printf("执行阶段 %d\n", i+1)
        }
        output = stage(output, cp.config)
    }
    
    return output
}

// 并发处理阶段
func concurrentProcessStage(process func(interface{}) interface{}) func(<-chan interface{}, PipelineConfig) <-chan interface{} {
    return func(input <-chan interface{}, config PipelineConfig) <-chan interface{} {
        output := make(chan interface{}, config.BufferSize)
        
        var wg sync.WaitGroup
        
        // 启动多个worker
        for i := 0; i < config.WorkerCount; i++ {
            wg.Add(1)
            go func() {
                defer wg.Done()
                for value := range input {
                    result := process(value)
                    output <- result
                }
            }()
        }
        
        go func() {
            wg.Wait()
            close(output)
        }()
        
        return output
    }
}

// 使用示例
func configurablePipelineExample() {
    config := PipelineConfig{
        BufferSize:    10,
        WorkerCount:   3,
        EnableLogging: true,
    }
    
    pipeline := NewConfigurablePipeline(config)
    
    // 添加阶段
    pipeline.AddStage(concurrentProcessStage(func(v interface{}) interface{} {
        if num, ok := v.(int); ok {
            return num * num // 平方
        }
        return v
    }))
    
    pipeline.AddStage(concurrentProcessStage(func(v interface{}) interface{} {
        if num, ok := v.(int); ok && num%2 == 0 {
            return num // 只返回偶数
        }
        return nil
    }))
    
    // 执行
    input := dataGenerator(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
    output := pipeline.Execute(input)
    
    for result := range output {
        if result != nil {
            fmt.Printf("Pipeline结果: %v\n", result)
        }
    }
}
```

## 3. Fan-out/Fan-in模式

### 基本Fan-out/Fan-in
```go
// Fan-out: 将工作分发给多个goroutines
func fanOut(input <-chan int, workerCount int) []<-chan int {
    workers := make([]<-chan int, workerCount)
    
    for i := 0; i < workerCount; i++ {
        worker := make(chan int)
        workers[i] = worker
        
        go func(output chan<- int) {
            defer close(output)
            for value := range input {
                // 模拟处理时间
                time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)
                output <- value * value
            }
        }(worker)
    }
    
    return workers
}

// Fan-in: 将多个goroutines的结果合并
func fanIn(inputs []<-chan int) <-chan int {
    output := make(chan int)
    var wg sync.WaitGroup
    
    for _, input := range inputs {
        wg.Add(1)
        go func(ch <-chan int) {
            defer wg.Done()
            for value := range ch {
                output <- value
            }
        }(input)
    }
    
    go func() {
        wg.Wait()
        close(output)
    }()
    
    return output
}

func fanOutFanInExample() {
    // 输入数据
    input := make(chan int)
    go func() {
        defer close(input)
        for i := 1; i <= 10; i++ {
            input <- i
        }
    }()
    
    // Fan-out到3个workers
    workers := fanOut(input, 3)
    
    // Fan-in合并结果
    output := fanIn(workers)
    
    // 收集结果
    var results []int
    for result := range output {
        results = append(results, result)
    }
    
    sort.Ints(results)
    fmt.Printf("Fan-out/Fan-in结果: %v\n", results)
}
```

### 动态Fan-out/Fan-in
```go
type DynamicFanProcessor struct {
    workerCount   int
    inputChan     chan interface{}
    outputChan    chan interface{}
    workerChans   []chan interface{}
    activeWorkers int64
    done          chan bool
}

func NewDynamicFanProcessor(initialWorkers int) *DynamicFanProcessor {
    return &DynamicFanProcessor{
        workerCount: initialWorkers,
        inputChan:   make(chan interface{}, 100),
        outputChan:  make(chan interface{}, 100),
        workerChans: make([]chan interface{}, 0),
        done:        make(chan bool),
    }
}

func (dfp *DynamicFanProcessor) Start() {
    // 启动初始workers
    for i := 0; i < dfp.workerCount; i++ {
        dfp.addWorker(i)
    }
    
    // 启动分发器
    go dfp.distributor()
    
    // 启动监控器
    go dfp.monitor()
}

func (dfp *DynamicFanProcessor) addWorker(id int) {
    workerChan := make(chan interface{}, 10)
    dfp.workerChans = append(dfp.workerChans, workerChan)
    
    go func(workerID int, input <-chan interface{}) {
        atomic.AddInt64(&dfp.activeWorkers, 1)
        defer atomic.AddInt64(&dfp.activeWorkers, -1)
        
        fmt.Printf("Worker %d 启动\n", workerID)
        
        for value := range input {
            // 模拟处理
            time.Sleep(time.Duration(rand.Intn(500)) * time.Millisecond)
            
            result := fmt.Sprintf("Worker-%d处理: %v", workerID, value)
            dfp.outputChan <- result
        }
        
        fmt.Printf("Worker %d 停止\n", workerID)
    }(id, workerChan)
}

func (dfp *DynamicFanProcessor) distributor() {
    for {
        select {
        case value := <-dfp.inputChan:
            // 轮询分发到workers
            workerIndex := rand.Intn(len(dfp.workerChans))
            select {
            case dfp.workerChans[workerIndex] <- value:
            default:
                // 如果worker忙，尝试其他worker
                for i := 0; i < len(dfp.workerChans); i++ {
                    select {
                    case dfp.workerChans[i] <- value:
                        goto distributed
                    default:
                    }
                }
                // 所有worker都忙，添加新worker
                newWorkerID := len(dfp.workerChans)
                dfp.addWorker(newWorkerID)
                dfp.workerChans[newWorkerID] <- value
            distributed:
            }
        case <-dfp.done:
            // 关闭所有worker channels
            for _, ch := range dfp.workerChans {
                close(ch)
            }
            return
        }
    }
}

func (dfp *DynamicFanProcessor) monitor() {
    ticker := time.NewTicker(1 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            active := atomic.LoadInt64(&dfp.activeWorkers)
            fmt.Printf("活跃Workers: %d, 总Workers: %d\n", active, len(dfp.workerChans))
        case <-dfp.done:
            return
        }
    }
}

func (dfp *DynamicFanProcessor) Submit(value interface{}) {
    dfp.inputChan <- value
}

func (dfp *DynamicFanProcessor) Results() <-chan interface{} {
    return dfp.outputChan
}

func (dfp *DynamicFanProcessor) Stop() {
    close(dfp.done)
    close(dfp.inputChan)
    time.Sleep(100 * time.Millisecond) // 等待清理
    close(dfp.outputChan)
}
```

## 4. 超时和取消模式

### Context-based 超时和取消
```go
import "context"

type CancellableTask struct {
    ID      int
    Process func(ctx context.Context) (interface{}, error)
}

func (ct *CancellableTask) Execute(ctx context.Context) (interface{}, error) {
    resultChan := make(chan interface{}, 1)
    errorChan := make(chan error, 1)
    
    go func() {
        result, err := ct.Process(ctx)
        if err != nil {
            errorChan <- err
        } else {
            resultChan <- result
        }
    }()
    
    select {
    case result := <-resultChan:
        return result, nil
    case err := <-errorChan:
        return nil, err
    case <-ctx.Done():
        return nil, ctx.Err()
    }
}

// 超时任务执行器
type TimeoutExecutor struct {
    defaultTimeout time.Duration
}

func NewTimeoutExecutor(timeout time.Duration) *TimeoutExecutor {
    return &TimeoutExecutor{
        defaultTimeout: timeout,
    }
}

func (te *TimeoutExecutor) Execute(task *CancellableTask) (interface{}, error) {
    ctx, cancel := context.WithTimeout(context.Background(), te.defaultTimeout)
    defer cancel()
    
    return task.Execute(ctx)
}

func (te *TimeoutExecutor) ExecuteWithCustomTimeout(task *CancellableTask, timeout time.Duration) (interface{}, error) {
    ctx, cancel := context.WithTimeout(context.Background(), timeout)
    defer cancel()
    
    return task.Execute(ctx)
}

// 可取消的任务管理器
type TaskManager struct {
    tasks   map[int]*CancellableTask
    cancels map[int]context.CancelFunc
    mu      sync.RWMutex
}

func NewTaskManager() *TaskManager {
    return &TaskManager{
        tasks:   make(map[int]*CancellableTask),
        cancels: make(map[int]context.CancelFunc),
    }
}

func (tm *TaskManager) StartTask(task *CancellableTask) <-chan interface{} {
    tm.mu.Lock()
    defer tm.mu.Unlock()
    
    ctx, cancel := context.WithCancel(context.Background())
    tm.tasks[task.ID] = task
    tm.cancels[task.ID] = cancel
    
    resultChan := make(chan interface{}, 1)
    
    go func() {
        defer func() {
            tm.mu.Lock()
            delete(tm.tasks, task.ID)
            delete(tm.cancels, task.ID)
            tm.mu.Unlock()
        }()
        
        result, err := task.Execute(ctx)
        if err != nil {
            resultChan <- fmt.Errorf("任务 %d 错误: %w", task.ID, err)
        } else {
            resultChan <- result
        }
    }()
    
    return resultChan
}

func (tm *TaskManager) CancelTask(taskID int) bool {
    tm.mu.RLock()
    cancel, exists := tm.cancels[taskID]
    tm.mu.RUnlock()
    
    if exists {
        cancel()
        return true
    }
    return false
}

func (tm *TaskManager) CancelAllTasks() {
    tm.mu.Lock()
    defer tm.mu.Unlock()
    
    for _, cancel := range tm.cancels {
        cancel()
    }
}

func (tm *TaskManager) GetActiveTasks() []int {
    tm.mu.RLock()
    defer tm.mu.RUnlock()
    
    taskIDs := make([]int, 0, len(tm.tasks))
    for id := range tm.tasks {
        taskIDs = append(taskIDs, id)
    }
    return taskIDs
}

// 使用示例
func timeoutCancelExample() {
    tm := NewTaskManager()
    
    // 创建一些任务
    tasks := []*CancellableTask{
        {
            ID: 1,
            Process: func(ctx context.Context) (interface{}, error) {
                for i := 0; i < 10; i++ {
                    select {
                    case <-ctx.Done():
                        return nil, ctx.Err()
                    default:
                        time.Sleep(100 * time.Millisecond)
                    }
                }
                return "任务1完成", nil
            },
        },
        {
            ID: 2,
            Process: func(ctx context.Context) (interface{}, error) {
                select {
                case <-time.After(2 * time.Second):
                    return "任务2完成", nil
                case <-ctx.Done():
                    return nil, ctx.Err()
                }
            },
        },
    }
    
    // 启动任务
    resultChans := make([]<-chan interface{}, len(tasks))
    for i, task := range tasks {
        resultChans[i] = tm.StartTask(task)
    }
    
    // 1秒后取消任务2
    go func() {
        time.Sleep(1 * time.Second)
        if tm.CancelTask(2) {
            fmt.Println("任务2已取消")
        }
    }()
    
    // 收集结果
    for i, resultChan := range resultChans {
        result := <-resultChan
        fmt.Printf("任务%d结果: %v\n", i+1, result)
    }
    
    fmt.Printf("活跃任务: %v\n", tm.GetActiveTasks())
}
```

## 5. 生产者-消费者模式

### 多生产者多消费者
```go
type Message struct {
    ID       int
    Content  string
    Priority int
}

type MessageQueue struct {
    messages chan Message
    done     chan bool
    wg       sync.WaitGroup
}

func NewMessageQueue(bufferSize int) *MessageQueue {
    return &MessageQueue{
        messages: make(chan Message, bufferSize),
        done:     make(chan bool),
    }
}

func (mq *MessageQueue) Producer(id int, messageCount int) {
    mq.wg.Add(1)
    
    go func() {
        defer mq.wg.Done()
        
        for i := 0; i < messageCount; i++ {
            msg := Message{
                ID:       i,
                Content:  fmt.Sprintf("Producer-%d-Message-%d", id, i),
                Priority: rand.Intn(5) + 1,
            }
            
            select {
            case mq.messages <- msg:
                fmt.Printf("生产者 %d 发送: %s\n", id, msg.Content)
                time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)
            case <-mq.done:
                fmt.Printf("生产者 %d 停止\n", id)
                return
            }
        }
        
        fmt.Printf("生产者 %d 完成\n", id)
    }()
}

func (mq *MessageQueue) Consumer(id int) {
    mq.wg.Add(1)
    
    go func() {
        defer mq.wg.Done()
        
        for {
            select {
            case msg := <-mq.messages:
                fmt.Printf("消费者 %d 处理: %s (优先级: %d)\n", id, msg.Content, msg.Priority)
                
                // 模拟处理时间（高优先级消息处理更快）
                processingTime := time.Duration((6-msg.Priority)*50) * time.Millisecond
                time.Sleep(processingTime)
                
            case <-mq.done:
                fmt.Printf("消费者 %d 停止\n", id)
                return
            }
        }
    }()
}

func (mq *MessageQueue) Stop() {
    close(mq.done)
    mq.wg.Wait()
    close(mq.messages)
}

func producerConsumerExample() {
    mq := NewMessageQueue(10)
    
    // 启动3个生产者
    for i := 1; i <= 3; i++ {
        mq.Producer(i, 5)
    }
    
    // 启动2个消费者
    for i := 1; i <= 2; i++ {
        mq.Consumer(i)
    }
    
    // 等待一段时间后停止
    time.Sleep(3 * time.Second)
    mq.Stop()
    
    fmt.Println("生产者-消费者示例完成")
}
```

### 优先级队列
```go
import "container/heap"

type PriorityMessage struct {
    Message
    Index int
}

type PriorityQueue []*PriorityMessage

func (pq PriorityQueue) Len() int { return len(pq) }

func (pq PriorityQueue) Less(i, j int) bool {
    return pq[i].Priority > pq[j].Priority // 高优先级在前
}

func (pq PriorityQueue) Swap(i, j int) {
    pq[i], pq[j] = pq[j], pq[i]
    pq[i].Index = i
    pq[j].Index = j
}

func (pq *PriorityQueue) Push(x interface{}) {
    n := len(*pq)
    item := x.(*PriorityMessage)
    item.Index = n
    *pq = append(*pq, item)
}

func (pq *PriorityQueue) Pop() interface{} {
    old := *pq
    n := len(old)
    item := old[n-1]
    old[n-1] = nil
    item.Index = -1
    *pq = old[0 : n-1]
    return item
}

type PriorityMessageQueue struct {
    queue   *PriorityQueue
    mu      sync.Mutex
    cond    *sync.Cond
    closed  bool
}

func NewPriorityMessageQueue() *PriorityMessageQueue {
    pq := &PriorityQueue{}
    heap.Init(pq)
    
    pmq := &PriorityMessageQueue{
        queue: pq,
    }
    pmq.cond = sync.NewCond(&pmq.mu)
    
    return pmq
}

func (pmq *PriorityMessageQueue) Enqueue(msg Message) {
    pmq.mu.Lock()
    defer pmq.mu.Unlock()
    
    if pmq.closed {
        return
    }
    
    priorityMsg := &PriorityMessage{Message: msg}
    heap.Push(pmq.queue, priorityMsg)
    pmq.cond.Signal()
}

func (pmq *PriorityMessageQueue) Dequeue() (Message, bool) {
    pmq.mu.Lock()
    defer pmq.mu.Unlock()
    
    for pmq.queue.Len() == 0 && !pmq.closed {
        pmq.cond.Wait()
    }
    
    if pmq.closed && pmq.queue.Len() == 0 {
        return Message{}, false
    }
    
    priorityMsg := heap.Pop(pmq.queue).(*PriorityMessage)
    return priorityMsg.Message, true
}

func (pmq *PriorityMessageQueue) Close() {
    pmq.mu.Lock()
    defer pmq.mu.Unlock()
    
    pmq.closed = true
    pmq.cond.Broadcast()
}
```

## 6. 实践练习

### 练习1：任务调度器
```go
// 实现一个支持优先级和延迟执行的任务调度器
type TaskScheduler struct {
    // 支持立即执行、延迟执行、周期执行
    // 支持任务优先级
    // 支持任务取消
}
```

### 练习2：限流器
```go
// 实现一个令牌桶限流器
type TokenBucketLimiter struct {
    // 支持突发流量
    // 支持动态调整速率
    // 支持多种限流策略
}
```

### 练习3：缓存系统
```go
// 实现一个带过期时间的LRU缓存
type CacheSystem struct {
    // 支持自动过期
    // 支持LRU淘汰策略
    // 支持并发安全
}
```

## 7. 参考资料

- [Go Concurrency Patterns](https://talks.golang.org/2012/concurrency.slide)
- [Advanced Go Concurrency Patterns](https://talks.golang.org/2013/advconc.slide)
- [Go语言并发模式](https://blog.golang.org/pipelines)
- [Context包文档](https://golang.org/pkg/context/)

---

通过本章的学习，你将掌握Go语言中常用的并发设计模式，能够根据不同的业务场景选择合适的并发模式，构建出高效、可维护的并发程序。